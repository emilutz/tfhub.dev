# Module emilutz/vgg19-block1-conv2-unpooling-encoder/1

Image encoder based on vgg19 that stores argmax values for maxpool layers.

<!-- asset-path: https://storage.googleapis.com/vgg19-with-unpooling/vgg19_block1_conv2/encoder.tar.gz -->
<!-- module-type: image-feature-vector -->
<!-- fine-tunable: true -->
<!-- dataset: COCO 2017 -->
<!-- format: saved_model_2 -->
<!-- license: MIT -->

## Overview

### Module description

This model accepts as input an image and outputs the features extracted from block1_conv2 level of VGG19. It served as a feature extractor for training an encoder-decoder structure based on VGG19 and is part of a larger collection of such pairs designed to offer the ability to manipulate images by changing the latent space. While training its corresponding decoder (which is a mirror of this model) the weights have been kept frozen. The pair was trained on the COCO 2017 dataset for 100 epochs using Adam optimizer with default parameters and a linear learning rate decay betwwen 0.001 and 0.0002.  

### Model architecture

### Input

### Output


## Usage

### Use SavedModel in Python

``
Code snippet demonstrating use (e.g. for a TF model using the tensorflow_hub library)

import tensorflow_hub as hub

model = hub.KerasLayer(<model name>)
inputs = ...
output = model(inputs)
``

## Performance


## Training

### Training dataset
